{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradyumnaGupta/Suggestion_Mining/blob/master/Colab_Sugg_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ZDYX_-1RL_",
        "colab_type": "code",
        "outputId": "0e54a535-a83a-41aa-c305-5554f343d850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "!pip install bert_tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert_tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocKr4kbb1pwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import backend as K\n",
        "from bert.tokenization import FullTokenizer\n",
        "import os \n",
        "import re\n",
        "from tqdm import tqdm_notebook\n",
        "import tqdm\n",
        "sess=tf.Session()\n",
        "#sess=tf.compat.v1.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ZYENjd2YCc",
        "colab_type": "code",
        "outputId": "034aca9b-78e0-41cf-fed1-aacf7a4e4330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data_train=pd.read_csv(\"train.csv\",header=None)\n",
        "data_val=pd.read_csv(\"val_taska.csv\",header=None)\n",
        "data_test=pd.read_csv(\"eval.csv\",header=None)\n",
        "print(data_train.shape)\n",
        "print(data_val.shape)\n",
        "print(data_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8455, 2)\n",
            "(592, 2)\n",
            "(833, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtMlqdKVn6ZL",
        "colab_type": "code",
        "outputId": "9f83acf2-2850-4033-99ac-13e661ba7a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "fig=plt.figure()\n",
        "sns.countplot(0,data=data_train)\n",
        "plt.show()\n",
        "\n",
        "print(\"Suggestion Class=\",sum(data_train.iloc[:,0]==1))\n",
        "print(\"Non-Suggestion Class=\",sum(data_train.iloc[:,0]==0))\n",
        "print(\"Ratio=\",sum(data_train.iloc[:,0]==1)/sum(data_train.iloc[:,0]==0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAESCAYAAAAv0qjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Suggestion Class= 2079\n",
            "Non-Suggestion Class= 6376\n",
            "Ratio= 0.3260664993726474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E0Hdpmm2g9u",
        "colab_type": "code",
        "outputId": "d7b7e32a-b36b-4a77-d468-cc0ad2314e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_seq_length=max([len(x) for x in tqdm.tqdm(data_train.iloc[:,1])])\n",
        "print(max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8455/8455 [00:00<00:00, 769125.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWyLa5Qk2kay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "max_seq_length=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBdhhBss2pzb",
        "colab_type": "code",
        "outputId": "f0741550-3a1c-4900-eb10-70a5e52ec05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Create datasets (Only take up to max_seq_length words for memory)\n",
        "train_text = data_train.iloc[:,1].tolist()\n",
        "train_text = [' '.join(t.split()[0:max_seq_length]) for t in tqdm.tqdm(train_text)]\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "train_label = data_train.iloc[:,0].tolist()\n",
        "\n",
        "test_text = data_test.iloc[:,1].tolist()\n",
        "test_text = [' '.join(t.split()[0:max_seq_length]) for t in tqdm.tqdm(test_text)]\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "test_label = data_test.iloc[:,0].tolist()\n",
        "\n",
        "val_text = data_val.iloc[:,1].tolist()\n",
        "val_text = [' '.join(t.split()[0:max_seq_length]) for t in tqdm.tqdm(val_text)]\n",
        "val_text = np.array(val_text, dtype=object)[:, np.newaxis]\n",
        "val_label = data_val.iloc[:,0].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8455/8455 [00:00<00:00, 355898.96it/s]\n",
            "100%|██████████| 833/833 [00:00<00:00, 323475.16it/s]\n",
            "100%|██████████| 592/592 [00:00<00:00, 260330.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgsB8tf42r5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxHv_6x2uPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "  pass\n",
        "def create_tokenizer_from_hub_module():\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    bert_module =  hub.Module(bert_path)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "def convert_single_example(tokenizer, example, max_seq_length=max_seq_length):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label\n",
        "\n",
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=max_seq_length):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels).reshape(-1, 1),\n",
        "    )\n",
        "def convert_text_to_examples(texts, labels):\n",
        "    \"\"\"Create InputExamples\"\"\"\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24vqBajk2zDh",
        "colab_type": "code",
        "outputId": "46184eae-7bb6-4a70-d874-afa920863f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "tokenizer = create_tokenizer_from_hub_module()\n",
        "train_examples = convert_text_to_examples(train_text, train_label)\n",
        "test_examples = convert_text_to_examples(test_text, test_label)\n",
        "val_examples = convert_text_to_examples(val_text, val_label)\n",
        "# Convert to features\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
        ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n",
        "(val_input_ids, val_input_masks, val_segment_ids, val_labels\n",
        ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da7af82ad6c44f3a8bd0204d0ca401de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=8455, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a9b4d890bc4cd692ae2e779b88dfff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=833, style=ProgressStyl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1c63b3ba4a8427f9fcb51c15dc0ab15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=592, style=ProgressStyl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3YT10oo23eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import keras\n",
        "class BertLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(\n",
        "            bert_path,\n",
        "            trainable=True,# did this in place of self.trainable\n",
        "            name=\"{}_module\".format(self.name)\n",
        "        )\n",
        "\n",
        "        trainable_vars = self.bert.variables\n",
        "\n",
        "        \n",
        "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "\n",
        "        # Select how many layers to fine tune\n",
        "        #trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
        "\n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "            \n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:\n",
        "                self._non_trainable_weights.append(var)\n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "            \"pooled_output\"\n",
        "        ]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P2f5_dL2_ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EesEt-46CL4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [3e-4]:\n",
        "    for epochs in [1]:\n",
        "        for dropout in [0.3]:\n",
        "            for layers in [2]: \n",
        "                #with tf.device('/GPU:2'):\n",
        "                sess=tf.Session()\n",
        "                #sess=tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
        "                from tensorflow.keras.layers import Input,Dense\n",
        "                in_id=Input(shape=(max_seq_length,),)\n",
        "                in_mask=Input(shape=(max_seq_length,),)\n",
        "                in_segment=Input(shape=(max_seq_length,),)\n",
        "                in_id = tf.keras.layers.Input(shape=(max_seq_length,))\n",
        "                in_mask = tf.keras.layers.Input(shape=(max_seq_length,))\n",
        "                in_segment = tf.keras.layers.Input(shape=(max_seq_length,))\n",
        "                bert_inputs=[in_id,in_mask,in_segment]\n",
        "                bert_outputs=BertLayer(n_fine_tune_layers=10)(bert_inputs)\n",
        "                step=bert_outputs\n",
        "                if layers>=3:\n",
        "                    step=tf.keras.layers.Dense(512,activation='relu')(step)\n",
        "                    if dropout!=0:\n",
        "                        step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "                if layers>=2:\n",
        "                    step=tf.keras.layers.Dense(256,activation='relu')(step)\n",
        "                    if dropout!=0:\n",
        "                        step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "                if layers>=1:    \n",
        "                    step=tf.keras.layers.Dense(64,activation='relu')(step)\n",
        "                    if dropout!=0:\n",
        "                        step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "                pred=tf.keras.layers.Dense(1,activation='sigmoid')(step)\n",
        "                model=tf.keras.Model(inputs=bert_inputs,outputs=pred)\n",
        "                model.compile(loss='binary_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "                        metrics=[f1,'accuracy'])\n",
        "          #tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,\n",
        "                                                        #strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu_address)))\n",
        "\n",
        "                sess.run(tf.local_variables_initializer())\n",
        "                sess.run(tf.global_variables_initializer())\n",
        "                sess.run(tf.tables_initializer())\n",
        "                K.set_session(sess)\n",
        "                #model=tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "\n",
        "                model.fit([train_input_ids, train_input_masks, train_segment_ids],\n",
        "                        train_labels,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=32,\n",
        "                        validation_data=([val_input_ids, val_input_masks, val_segment_ids],val_labels))\n",
        "                        \n",
        "                from sklearn.metrics import f1_score,accuracy_score\n",
        "                predict=model.predict([test_input_ids,test_input_masks,test_segment_ids])>0.5\n",
        "                print(\"task_a=\",f1_score(test_labels,predict),\"  acc=\",accuracy_score(test_labels,predict))\n",
        "                predict2=model.predict([test2_input_ids,test2_input_masks,test2_segment_ids])>0.5\n",
        "                print(\"task_b=\",f1_score(test2_labels,predict2),\"    acc=\",accuracy_score(test2_labels,predict2))                        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6VySu5GDVnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayer(tf.keras.layers.Layer):\n",
        "                    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
        "                        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "                        self.trainable = True\n",
        "                        self.output_size = 768\n",
        "                        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "                    def build(self, input_shape):\n",
        "                        self.bert = hub.Module(\n",
        "                        bert_path,\n",
        "                        trainable=True,# did this in place of self.trainable\n",
        "                        name=\"{}_module\".format(self.name)\n",
        "                      )\n",
        "\n",
        "                        trainable_vars = self.bert.variables\n",
        "\n",
        "\n",
        "                        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "                        #print(\"--------------------------len=\",len(trainable_vars))\n",
        "                        # Select how many layers to fine tune\n",
        "                        trainable_vars = trainable_vars[-self.n_fine_tune_layers:]\n",
        "\n",
        "                        # Add to trainable weights\n",
        "                        for var in trainable_vars:\n",
        "                            self._trainable_weights.append(var)\n",
        "\n",
        "                        for var in self.bert.variables:\n",
        "                            if var not in self._trainable_weights:\n",
        "                                self._non_trainable_weights.append(var)\n",
        "\n",
        "                        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "                    def call(self, inputs):\n",
        "                        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "                        input_ids, input_mask, segment_ids = inputs\n",
        "                        bert_inputs = dict(\n",
        "                          input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "                      )\n",
        "                        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                          \"pooled_output\"\n",
        "                      ]\n",
        "                        return result\n",
        "\n",
        "                    def compute_output_shape(self, input_shape):\n",
        "                        return (input_shape[0], self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_jDPWOp6z2h",
        "colab_type": "code",
        "outputId": "5968dcbb-17b8-43ae-cbdf-74e500d820a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "with tf.keras.utils.CustomObjectScope({'BertLayer' : BertLayer(n_fine_tune_layers=10)}):\n",
        "    with tf.keras.utils.CustomObjectScope({'f1':f1}):    \n",
        "        model=tf.keras.models.load_model('my_model.h5')\n",
        "        model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer (BertLayer)          (None, 768)          110104890   input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           16448       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 110,318,267\n",
            "Trainable params: 6,118,529\n",
            "Non-trainable params: 104,199,738\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVG-Qyi5zdoq",
        "colab_type": "code",
        "outputId": "c83ea140-5793-4de6-d136-c090ff6fac81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "predict=model.predict([test_input_ids,test_input_masks,test_segment_ids])>0.5\n",
        "print(\"task_a=\",f1_score(test_labels,predict),\"  acc=\",accuracy_score(test_labels,predict))\n",
        "#predict2=model.predict([test2_input_ids,test2_input_masks,test2_segment_ids])>0.5\n",
        "#print(\"task_b=\",f1_score(test2_labels,predict2),\"    acc=\",accuracy_score(test2_labels,predict2))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task_a= 0.770949720670391   acc= 0.9507803121248499\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}